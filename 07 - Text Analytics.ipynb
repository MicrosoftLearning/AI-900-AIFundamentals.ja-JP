{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Analytics\r\n",
        "\r\n",
        "自然言語処理 (NLP) は、書き言葉と話し言葉を扱う人工知能 (AI) の一分野です。NLP を使用して、テキストや音声から意味を抽出したり、意味のある応答を自然言語で作成したりするソリューションを構築できます。\r\n",
        "\r\n",
        "Microsoft Azure *Cognitive Services* には、テキスト内のキー フレーズの識別や、感情に基づくテキストの分類など、すぐに使用できる NLP 機能を提供する *Text Analytics* サービスが含まれています。\r\n",
        "\r\n",
        "![ノートを読んでいるロボット](./images/NLP.jpg)\r\n",
        "\r\n",
        "たとえば、架空の旅行会社 *Margie's Travel* が、ホテル滞在のレビューを提出するよう顧客に勧めているとします。Text Analytics サービスを使用すると、キー フレーズを抽出してレビューを要約したり、どのレビューが肯定的でどれが否定的であるかを判断したり、レビューの文面を分析して場所や人などの既知の事項について言及しているか確認したりできます。\r\n",
        "\r\n",
        "## レビュー ドキュメントを表示する\r\n",
        "\r\n",
        "まず、顧客から寄せられたホテルのレビューをいくつか見てみます。\r\n",
        "\r\n",
        "レビューはテキスト ファイルです。確認するには、セルの左側にある 「**セルの実行**」 (&#9655;) ボタンをクリックして、以下のコードを実行します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cognitive Services リソースを作成する\r\n",
        "\r\n",
        "**Text Analytics** Cognitive Service を使用すると、これらのレビューのテキストを分析できます。このサービスを使用するには、Azure サブスクリプションで **Text Analytics** リソースまたは **Cognitive Services** リソースのいずれかをプロビジョニングする必要があります。使用する予定のサービスは Text Analytics だけである場合、または Text Analytics の使用状況を個別に追跡する場合は、Text Analytics リソースを使用します。それ以外の場合は、Cognitive Services リソースを使用すると、Text Analytics サービスを他の Cognitive Services と組み合わせることができ、開発者が単一のエンドポイントとキーを使用してそれらのサービスにアクセスできるようになります。\r\n",
        "\r\n",
        "まだリソースを作成していない場合は、次の手順で Azure サブスクリプションに **Cognitive Services** リソースを作成します。\r\n",
        "\r\n",
        "> **注**: Cognitive Services リソースが既にある場合は、Azure portal で**クイック スタート**ページを開き、キーとエンドポイントを以下のセルにコピーするだけで作成できます。それ以外の場合は、以下の手順に従って作成してください。\r\n",
        "\r\n",
        "1. ブラウザーの新しいタブで Azure portal (https://portal.azure.com) を開き、Microsoft アカウントでサインインします。\r\n",
        "2. 「**&#65291;リソースの作成**」 ボタンをクリックし、*Cognitive Services* を検索して、以下の設定で **Cognitive Services** リソースを作成します。\r\n",
        "    - **サブスクリプション**: *使用する Azure サブスクリプション*\r\n",
        "    - **リソース グループ**: *一意の名前のリソース グループを選択または作成します*\r\n",
        "    - **リージョン**: *利用可能な任意のリージョンを選択します*。\r\n",
        "    - **名前**: *一意の名前を入力します*。\r\n",
        "    - **価格レベル**: S0\r\n",
        "    - **注意事項を読み理解しました**: 選択されています。\r\n",
        "3. デプロイが完了するまで待ちます。そのあと Cognitive Services リソースに移動し、「**概要**」 ページでリンクをクリックしてサービスのキーを管理します。クライアント アプリケーションから Cognitive Services リソースに接続するには、エンドポイントとキーが必要です。\r\n",
        "\r\n",
        "### Cognitive Services リソースのキーとエンドポイントを取得する\r\n",
        "\r\n",
        "Cognitive Services リソースを使用するには、クライアント アプリケーションにエンドポイントと認証キーが必要です。\r\n",
        "\r\n",
        "1. Azure portalで、Cognitive Services リソースの 「**キーとエンドポイント**」 ページからリソースの 「**キー 1**」 の値をコピーし、以下のコードに貼り付けます (**YOUR_COG_KEY** と置き換える)。\r\n",
        "2. リソースの**エンドポイント**をコピーして以下のコードに貼り付けます (**YOUR_COG_ENDPOINT** と置き換える)。\r\n",
        "3. 以下のセルの緑色の <span style=\"color:green\">&#9655;</span> ボタンをクリックして、コードを実行します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 言語を検出する\r\n",
        "最初に、書かれているレビューの言語を識別します。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## キー フレーズを抽出する\r\n",
        "\r\n",
        "これで、顧客レビューのテキストを分析して、主要な論点を示すキー フレーズを識別できます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "キー フレーズは、各レビューで最も重要な論点を理解するのに役立ちます。たとえば、「スタッフが親切」や「サービスがよくない」というフレーズを含むレビューは、顧客の主要な懸念事項を示している可能性があります。\r\n",
        "\r\n",
        "## 感情を判断する\r\n",
        "\r\n",
        "*感情スコア*に基づいて、レビューを*肯定的*か*否定的*かで分類すると役立つ場合があります。この分類も、Text Analytics サービスを使用して行うことができます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 既知のエンティティを抽出する\r\n",
        "\r\n",
        "*エンティティ*は、テキストの中で述べられている可能性のある事がらであり、一般的に理解されているタイプのものです。例えば、場所、人、日付などです。レビューに記載されている日付と場所に関心があるとします。その場合、次のコードを使用すると、それらのエンティティを見つけることができます。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "エンティティの中には、ウィキペディアのページが関連付けられていて十分に知られているものもあります。そのような場合、Text Analytics サービスはウィキペディアのページの URL を返します。\r\n",
        "\r\n",
        "## 詳細情報\r\n",
        "\r\n",
        "Text Analytics サービスの詳細については、「[Text Analytics サービス ドキュメント](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)」を参照してください。"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}