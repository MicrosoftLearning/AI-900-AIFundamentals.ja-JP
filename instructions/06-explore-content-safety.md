---
lab:
  title: Content Safety Studio について調べる
---

Azure AI サービスは、ユーザーがすぐに使用できる事前構築済みのカスタマイズ可能な API とモデルを使って AI アプリケーションを作成するのに役立ちます。 この演習では、サービスの 1 つである Azure AI Content Safety を Content Safety Studio で見ていきます。 

Content Safety Studio を使うと、テキストと画像のコンテンツがどのようにモデレートされるかを調べることができます。 サンプル テキストまたは画像に対してテストを実行し、カテゴリごとに安全から高までの重大度スコアを取得できます。 このラボ演習では、Content Safety Studio で単一サービス リソースを作成し、その機能をテストします。 

> **注** この演習の目的は、Azure AI サービスのプロビジョニングと使用方法について一般的に理解することです。 Content Safety を例として使用しますが、この演習ではコンテンツの安全性に関する包括的な知識を得ることは想定していません。

## Content Safety Studio 内を移動する 

![Content Safety Studio のランディング ページのスクリーンショット。](./media/content-safety/content-safety-getting-started.png)


1. [Content Safety Studio](https://contentsafety.cognitive.azure.com?azure-portal=true) を開きます。 ログインしていない場合は、サインインする必要があります。 画面の右上にある **[サインイン]** を選びます。 自分の Azure サブスクリプションに関連付けられているメール アドレスとパスワードを使ってサインインします。 

1. Content Safety Studio は、Azure AI サービス用の他の多くのスタジオと同様に設定されています。 画面の上部にあるメニューで、*Azure AI* の左側にあるアイコンをクリックします。 Azure AI サービスでの開発用に設計された他のスタジオのドロップダウン リストが表示されます。 アイコンをもう一度クリックすると、リストを非表示にできます。

![他のスタジオに切り替えるトグル選択が開いている Content Safety Studio のメニューのスクリーンショット。](./media/content-safety/studio-toggle-icon.png)  

## リソースをスタジオに関連付ける 

スタジオを使う前に、Azure AI サービス リソースをスタジオと関連付ける必要があります。 スタジオによっては、特定の単一サービス リソースが必要な場合や、一般的なマルチサービス リソースを使用できる場合があります。 Content Safety Studio の場合は、単一サービスである *Content Safety* リソースまたは "Azure AI サービス" の一般的なマルチサービス リソースを作成することで、サービスを使用できます。** 以下の手順では、単一サービスの Content Safety リソースを作成します。 

1. 画面の右上にある **[設定]** アイコンをクリックします。 

![画面の右上の、ベル、疑問符、スマイル アイコンの横にある設定アイコンのスクリーンショット。](./media/content-safety/settings-toggle.png)

1. **[設定]** ページには、[ディレクトリ] タブと [リソース] タブが表示されます。[リソース] タブで、 **[新しいリソースの作成]** を選びます。** ** ** これにより、Azure portal でリソースを作成するためのページが表示されます。

> **注** [ディレクトリ] タブでは、ユーザーはリソース作成の元になるさまざまなディレクトリを選択できます。** 異なるディレクトリを使うのでない限り、その設定を変更する必要はありません。 

![Content Safety Studio の設定ページで [新しいリソースの作成] を選ぶ場所のスクリーンショット。](./media/content-safety/create-new-resource-from-studio.png)

1. [Azure portal](https://portal.azure.com?auzre-portal=true) の [Content Safety の作成] ページでは、リソースを作成するためのいくつかの詳細を構成する必要があります。** これを以下の設定で構成します。
    - **[サブスクリプション]**: *お使いの Azure サブスクリプション*。
    - **[リソース グループ]**: *一意の名前のリソース グループを選択するか、作成します*。
    - **リージョン**: 使用できるリージョンを選択します**
    - **[名前]**: *一意の名前を入力します*。
    - **価格レベル**: Free F0

1. **[確認と作成]** を選んで、構成を確認します。 **[作成]** を選択します。 画面には、デプロイが完了した日時が示されます。 

"おめでとうございます。Azure AI サービス リソースの作成またはプロビジョニングが済みました。具体的には、プロビジョニングしたリソースは、単一サービスの Content Safety サービス リソースです。"**

1. デプロイが完了したら、新しいタブを開いて、[Content Safety Studio](https://contentsafety.cognitive.azure.com?azure-portal=true) に戻ります。 

1. 画面の右上の **[設定]** アイコンをもう一度選びます。 今度は、新しく作成したリソースが一覧に追加されていることがわかるはずです。  

1. Content Safety Studio の [設定] ページで、先ほど作成した Azure AI サービス リソースを選び、画面の下部にある **[リソースの使用]** をクリックします。 画面はスタジオのホーム ページに戻ります。 これで、新しく作成したリソースでスタジオを使い始めることができます。

## Content Safety Studio でテキスト モデレーションを試す

1. Content Safety Studio のホーム ページの [Run moderation tests] (モデレーションのテストを実行する) の下で、 **[Moderate text content] (テキストのコンテンツをモデレートする)** ボックスに移動し、 **[試してみる]** をクリックします。**
1. [run a simple test] (簡単なテストの実行) で、 **[Safe Content] (安全なコンテンツ)** をクリックします。 下のボックスにテキストが表示されることに注目してください。 
1. **[テストの実行]** をクリックします。 テストを実行すると、Content Safety Service のディープ ラーニング モデルが呼び出されます。 ディープ ラーニング モデルは、安全でないコンテンツを認識するように既にトレーニングされています。
1. [結果] パネルで結果を調べます。** 重大度レベルは安全から高まで 4 段階、有害なコンテンツは 4 種類あります。 Content Safety AI サービスはこのサンプルを許容範囲内と判断するでしょうか。 注意すべき重要な点は、結果が信頼区間内にあるということです。 Azure AI のすぐに使用できるモデルのように、十分にトレーニングされたモデルは、人間が結果に付けるラベルと一致する可能性が高い結果を返すことができます。 テストを実行するたびに、モデルを再度呼び出します。 
1. 次は別のサンプルを試してみましょう。 [Violent content with misspelling] (スペルミスのある暴力的なコンテンツ) の下のテキストを選びます。 下のボックスにコンテンツが表示されていることを確認します。
1. **[テストの実行]** をクリックし、[結果] パネルでもう一度結果を調べます。 

提供されているすべてのサンプルに対してテストを実行し、結果を調べることができます。

## キーとエンドポイントを確認する

テストしたこれらの機能は、あらゆる種類のアプリケーションにプログラミングできます。 アプリケーションの開発に使われるキーとエンドポイントは、Content Safety Studio と Azure portal の両方で確認できます。 

1. Content Safety Studio で **[設定]** ページに戻り、[リソース] タブを選びます。** 使ったリソースを探します。 スクロールして、リソースのエンドポイントとキーを確認します。 
1. Azure portal では、これらがリソースに対する "同じ" エンドポイントと "異なる" キーであることがわかります。** ** 調べるには、[Azure portal](https://portal.azure.com?auzre-portal=true) に移動します。 上部の検索バーで *Content Safety* を検索します。 リソースを見つけて、それをクリックします。 左側のメニューの [リソースの管理] で [Keys and Endpoints] (キーとエンドポイント) を見つけます。** ** **[Keys and Endpoints] (キーとエンドポイント)** を選んで、リソースのエンドポイントとキーを表示します。 

済んだら、Azure portal から Content Safety リソースを削除してかまいません。 リソースを削除すると、リソースがサブスクリプションに存在していると発生するコストを削減できます。 これを行うには、Content Safety リソースの **[概要]** ページに移動します。 画面の最上部で **[削除]** を選びます。 
